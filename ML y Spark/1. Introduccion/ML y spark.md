## Machine Learning con Apache Spark üß†

El objetivo es **construir modelos de aprendizaje autom√°tico** (ML) con conjuntos de datos masivos (Big Data) **utilizando t√©cnicas de computaci√≥n distribuida**.

### El Problema: El "Hotcake Perfecto" a Gran Escala ü•û

Podemos pensar en el ML como un proceso para encontrar la "receta del hotcake perfecto".

1.  **Enfoque Tradicional:** Le presentamos a la computadora una receta y aprende de ella.
2.  **Enfoque ML:** Le presentamos una **selecci√≥n de miles o millones de recetas** (los datos), y el modelo **descubrir√° los mejores ingredientes y proporciones** (los par√°metros) para predecir el mejor resultado (ej. la calificaci√≥n del hotcake).

#### ¬øC√≥mo Funciona el Aprendizaje Autom√°tico?

La computadora **aprende de ejemplos**. En el aprendizaje supervisado (el m√°s com√∫n), esto se divide en:

* **Regresi√≥n:** Predecir un valor que **generalmente es num√©rico** y continuo.
    * *Ejemplo:* ¬ø**Cu√°nta harina** se deber√° poner para un hotcake de 10 cm?
* **Clasificaci√≥n:** Predecir un **valor discreto o categ√≥rico** (una etiqueta).
    * *Ejemplo:* ¬øEste ingrediente es "sal" o es "az√∫car"?

---

### El L√≠mite de una Sola M√°quina: El Cuello de Botella

Cuando el conjunto de datos es peque√±o, **si los datos caben en la memoria RAM** de una computadora, el procesamiento es r√°pido.

* **El Problema:** Cuando el conjunto de datos es masivo (Big Data), no cabe en la RAM. El sistema operativo utiliza la **memoria virtual** (espacio en el disco duro) y los **datos se "paginar√°n"** (se mueven constantemente entre el disco y la RAM).
* **La Consecuencia:** Esto hace que **el rendimiento se desplome**, ya que el acceso al disco es miles de veces m√°s lento que el acceso a la RAM.

La soluci√≥n es **distribuir el procesamiento** en m√∫ltiples m√°quinas, y **este es el enfoque de Spark**.

---

### Apache Spark: La Soluci√≥n Distribuida üöÄ

Spark es un **marco (framework) de prop√≥sito general para la computaci√≥n en cl√∫ster**.

* **Velocidad:** Es mucho **m√°s r√°pido que marcos tradicionales** de Big Data (como el MapReduce de Hadoop), porque **realiza la mayor parte del procesamiento en memoria (in-memory)** a trav√©s de los diferentes nodos del cl√∫ster.
* **Interfaz Amigable:** Provee una API de alto nivel (en Scala, Python, R, SQL) que **oculta la complejidad de la computaci√≥n distribuida**.
* **Spark MLlib:** Es la biblioteca espec√≠fica de Spark dise√±ada para realizar Machine Learning de forma distribuida, aprovechando toda la arquitectura del cl√∫ster.

---

### üèóÔ∏è Arquitectura B√°sica de Spark

Spark funciona coordinando un conjunto de computadoras (un cl√∫ster).

* **Cl√∫ster:** Consta de varios **Nodos** (Workers). Cada nodo es una computadora individual con su propia CPU, RAM y almacenamiento f√≠sico.
* **Componentes Clave:**
    * **Administrador de Cl√∫ster (Cluster Manager):** Es el software que **asigna los recursos** de hardware a las aplicaciones (ej. YARN, Mesos o el propio de Spark).
    * **Programa Controlador (Driver):** Cada aplicaci√≥n que se ejecuta en el cl√∫ster (ej. tu script de ML) tiene un **programa controlador** (es el `main()` de tu app).
    * **Ejecutor (Executor):** Es un proceso que Spark lanza en cada nodo. Este proceso **persiste mientras dura la aplicaci√≥n** y es el que realmente hace el trabajo.

#### Flujo de Funcionamiento

1.  Al utilizar la API de Spark, el **Controlador (Driver)** se comunica con el **Administrador del Cl√∫ster**.
2.  El Administrador, a su vez, **distribuye el trabajo** a los nodos disponibles, asignando **Ejecutores** para la aplicaci√≥n.
3.  El trabajo se divide en **Tareas (Tasks)**, que son las unidades m√≠nimas de c√°lculo (ej. procesar una partici√≥n de los datos).
4.  Los **Ejecutores** en cada nodo ejecutan estas tareas, a menudo usando m√∫ltiples **subprocesos (threads)** en los diferentes n√∫cleos (cores) del nodo para lograr el paralelismo.