Este es un excelente proyecto de **Selecci√≥n de Caracter√≠sticas (Feature Selection)**. Como experto en Machine Learning, tu objetivo es determinar cu√°l de los par√°metros del suelo (Nitr√≥geno, F√≥sforo, Potasio o pH) es el "ganador" en t√©rminos de poder predictivo individual.

Este problema es muy com√∫n en **ingenier√≠a de datos y despliegue (DevOps)**: a veces, por presupuesto o latencia, no podemos recolectar todos los datos y debemos elegir el sensor m√°s eficiente.


---

## üåæ Proyecto: Identificaci√≥n de la Mejor Caracter√≠stica Predictiva

### 1. Diagn√≥stico y Preparaci√≥n

Primero, cargamos los datos y realizamos una revisi√≥n r√°pida. Siguiendo tus apuntes previos, lo primero es verificar si existen valores nulos que requieran un `SimpleImputer`.

```python
# 1. Carga de datos y revisi√≥n r√°pida
crops = pd.read_csv("soil_measures.csv")

# Verificar nulos (Basado en tu apunte de preprocesamiento)
print(crops.isna().sum())

# Verificar tipos de cultivos (Target)
print(crops["crop"].unique())
```

### 2. Divisi√≥n de Datos (Train/Test Split)

Separamos el conjunto de datos para asegurar que nuestra evaluaci√≥n sea honesta y evitar el **Data Leakage**.

```python
# 2. Definir X e y
X = crops.drop("crop", axis=1)
y = crops["crop"]

# Dividir en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

### 3. Evaluaci√≥n de Caracter√≠sticas Individuales

Aqu√≠ aplicamos un bucle para entrenar un modelo de **Regresi√≥n Log√≠stica** utilizando **solo una caracter√≠stica a la vez**. Calcularemos el **F1-score**, que es ideal para clasificaci√≥n multiclase ya que equilibra la precisi√≥n y la sensibilidad (Recall).

```python
# 3. Evaluar cada caracter√≠stica por separado
feature_performance = {}

for feature in ["N", "P", "K", "ph"]:
    # Instanciar el modelo (Usando multinomial para multiclase)
    log_reg = LogisticRegression(max_iter=2000, multi_class="multinomial")
    
    # Entrenar usando solo una columna de X_train
    log_reg.fit(X_train[[feature]], y_train)
    
    # Predecir y evaluar
    y_pred = log_reg.predict(X_test[[feature]])
    
    # Usamos el F1-score ponderado (weighted) como m√©trica de √©xito
    score = metrics.f1_score(y_test, y_pred, average="weighted")
    
    feature_performance[feature] = score
    print(f"F1-score para {feature}: {score:.4f}")
```

### 4. Selecci√≥n del Ganador

Finalmente, identificamos cu√°l obtuvo el puntaje m√°s alto y lo almacenamos en el formato de diccionario solicitado.

```python
# 4. Encontrar la mejor caracter√≠stica
best_feature = max(feature_performance, key=feature_performance.get)
best_score = feature_performance[best_feature]

# Crear la variable final
best_predictive_feature = {best_feature: best_score}

print(f"\n‚úÖ La mejor caracter√≠stica es: {best_predictive_feature}")
```

---

## üß† An√°lisis T√©cnico para tu Carrera

Desde la perspectiva de **Ingenier√≠a y MLOps**, este ejercicio nos ense√±a tres cosas fundamentales:

1. **Eficiencia de Costos:** Al identificar que (por ejemplo) el **Potasio (K)** o el **Nitr√≥geno (N)** tienen un 70% de precisi√≥n por s√≠ solos, el granjero puede ahorrar el 75% de su presupuesto de sensores sacrificando solo un margen aceptable de error.
    
2. **M√©trica $F1-Score$:** En problemas multiclase con cultivos, no usamos solo _Accuracy_. El F1-score es la media arm√≥nica entre precisi√≥n y recall, lo que nos asegura que el modelo es bueno identificando todos los tipos de cultivos, no solo el m√°s frecuente.
    
    $$F1 = 2 \cdot \frac{\text{precisi√≥n} \cdot \text{recall}}{\text{precisi√≥n} + \text{recall}}$$
    
3. **Iteraci√≥n de Modelos:** Este patr√≥n de "probar y guardar en un diccionario" es el mismo que usamos en `GridSearchCV` para encontrar hiperpar√°metros. Est√°s automatizando la toma de decisiones.
    
