## Validaci칩n Cruzada (Cross-Validation)

Hasta ahora, hemos medido el rendimiento con un solo conjunto de prueba. Sin embargo, el valor de $R^2$ resultante depende totalmente de c칩mo se dividieron los datos aleatoriamente. Si el conjunto de prueba tiene datos "f치ciles", el modelo parecer치 mejor de lo que es; si tiene datos at칤picos, parecer치 peor. Para solucionar esta dependencia, utilizamos la t칠cnica de **k-fold Cross-Validation**.


El objetivo es implementar una validaci칩n cruzada de 6 pliegues (6-fold CV) para evaluar la estabilidad de un modelo de regresi칩n lineal sobre el conjunto de datos de ventas. Para asegurar que el proceso sea robusto, se deben barajar los datos antes de dividirlos y calcular no solo el promedio de los resultados, sino tambi칠n su desviaci칩n est치ndar y el intervalo de confianza del 95%.

```python
import numpy as np
from sklearn.model_selection import cross_val_score, KFold
from sklearn.linear_model import LinearRegression

# 1. Configurar el esquema de validaci칩n (KFold)
# Usamos shuffle=True para evitar sesgos si los datos est치n ordenados
kf = KFold(n_splits=6, shuffle=True, random_state=42)

# 2. Instanciar el modelo
reg = LinearRegression()

# 3. Ejecutar la validaci칩n cruzada
# Por defecto, devuelve R-cuadrado para regresi칩n lineal
cv_results = cross_val_score(reg, X, y, cv=kf)

# 4. Evaluaci칩n estad칤stica de los resultados
print("Resultados de cada pliegue:", cv_results)
print("Media de R^2: {}".format(np.mean(cv_results)))
print("Desviaci칩n est치ndar: {}".format(np.std(cv_results)))

# 5. Calcular el intervalo de confianza del 95%
print("Intervalo de confianza (95%):", np.quantile(cv_results, [0.025, 0.975]))
```

---

### Fundamentos y Complementos T칠cnicos

#### 쮺칩mo funciona el proceso de "Folds"?

Imagina que divides tus datos en 5 grupos ($k=5$):

1. **Iteraci칩n 1:** El grupo 1 es el examen (test), los grupos 2, 3, 4 y 5 son el estudio (entrenamiento).
    
2. **Iteraci칩n 2:** El grupo 2 es el examen, los dem치s son el estudio.
    
3. **... as칤 sucesivamente** hasta que todos los grupos hayan sido "el examen" una vez.
    

Al final, no tienes un solo $R^2$, tienes 5. Esto te permite ver qu칠 tanto **var칤a** el rendimiento del modelo dependiendo de los datos que vea.

#### El Compromiso (Trade-off) de $k$

- **$k$ alto (ej. 10 o m치s):** El modelo es evaluado de forma m치s exhaustiva, pero el costo computacional aumenta dr치sticamente (tienes que entrenar el modelo 10 veces).
    
- **$k$ bajo (ej. 5):** Es m치s r치pido, pero existe un ligero riesgo de que los resultados sigan siendo un poco dependientes de la suerte del split.
    

#### Estad칤sticas Cr칤ticas

- **Media (Mean):** Es tu "verdadera" m칠trica de rendimiento.
    
- **Desviaci칩n Est치ndar (Std):** Mide la **consistencia**. Si la media es 0.80 pero la desviaci칩n es 0.20, tu modelo es inestable (a veces es excelente y a veces falla). Queremos una desviaci칩n est치ndar lo m치s peque침a posible.
    
- **Intervalo de Confianza:** Nos dice que, con un 95% de seguridad, el rendimiento del modelo en el mundo real estar치 entre esos dos valores (l칤mite inferior y superior).
    

> 游눠 **Analog칤a del Estudiante:** La validaci칩n cruzada es como hacer 5 ex치menes parciales diferentes a lo largo del semestre en lugar de jugarse toda la nota en un solo examen final. El promedio de esos 5 ex치menes refleja mucho mejor tu conocimiento real que una sola prueba donde podr칤as haber estado nervioso o haber tenido suerte con las preguntas.
