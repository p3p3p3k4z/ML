## El Reto de la Clasificaci√≥n: Algoritmo KNN

La clasificaci√≥n es el proceso de construir un modelo (clasificador) que aprende de datos etiquetados para predecir la etiqueta de datos nuevos (no vistos).

### ¬øQu√© es k-Nearest Neighbors (KNN)?

La idea central de KNN es simple: **"Dime con qui√©n andas y te dir√© qui√©n eres"**. Para predecir la etiqueta de un punto de datos desconocido, el algoritmo mira a los $k$ puntos etiquetados m√°s cercanos y toma una decisi√≥n.

- **Votaci√≥n por Mayor√≠a:** El modelo cuenta las etiquetas de esos $k$ vecinos y asigna al punto nuevo la etiqueta que tenga la mayor√≠a.
    

> üí° **Analog√≠a del vecindario:** Imagina que te mudas a una casa pero no sabes si el barrio es "Ruidoso" o "Tranquilo". Preguntas a tus 3 vecinos m√°s cercanos ($k=3$). Si dos dicen "Ruidoso" y uno dice "Tranquilo", t√∫ clasificas tu casa como "Ruidosa" por votaci√≥n de mayor√≠a.

### El Impacto de "k"

El valor de $k$ es un **hiperpar√°metro** (un ajuste que t√∫ eliges) y puede cambiar totalmente el resultado:

- **Si $k=3$:** Se miran los 3 vecinos m√°s cercanos. Si 2 son rojos y 1 es azul, el nuevo punto ser√° **Rojo**.
    
- **Si $k=5$:** Se ampl√≠a el c√≠rculo. Si ahora hay 3 azules y 2 rojos, el mismo punto ser√° clasificado como **Azul**.
    

### Intuici√≥n y Frontera de Decisi√≥n

Cuando un modelo KNN termina de "aprender", divide el espacio de los datos en regiones. A esto se le llama **Frontera de Decisi√≥n (Decision Boundary)**.

- **√Årea de Predicci√≥n:** Es como un mapa pol√≠tico. Si un nuevo dato cae en la "zona gris", el modelo predice autom√°ticamente una etiqueta (ej. el cliente se ir√° de la empresa / _churn_). Si cae en la "zona roja", predice otra (ej. el cliente se queda).
    

---

### Implementaci√≥n T√©cnica con scikit-learn

Para usar KNN en c√≥digo, debemos seguir reglas espec√≠ficas sobre c√≥mo estructurar la informaci√≥n.

#### La forma de los datos (Shapes)

Scikit-learn es muy estricto con las dimensiones de tus matrices:

- **Variable $X$ (Atributos):** Debe ser un array de **2 dimensiones**. Imaginalo como una tabla de Excel donde cada columna es una caracter√≠stica (ej. precio, tama√±o) y cada fila es una observaci√≥n.
    
- **Variable $y$ (Objetivo):** Debe ser un array de **1 dimensi√≥n**. Es una sola columna con las etiquetas (ej. 0 o 1).
    

> üõ†Ô∏è **Nota t√©cnica:** Usamos el atributo `.values` de pandas para convertir nuestras tablas en **arrays de NumPy**, que es el formato de bajo nivel que scikit-learn procesa m√°s r√°pido.

#### El proceso en c√≥digo

Python

```
from sklearn.neighbors import KNeighborsClassifier

# 1. Instanciar el modelo (Elegimos k=15)
knn = KNeighborsClassifier(n_neighbors=15)

# 2. Ajustar (Fit) el modelo
# Aqu√≠ el modelo "se sit√∫a" en el mapa de los datos etiquetados
knn.fit(X, y)

# 3. Predecir (Predict)
# Pasamos datos nuevos (X_new) para ver qu√© etiquetas les asigna
predictions = knn.predict(X_new)
```

Al imprimir las predicciones, obtendr√°s valores binarios (como `1` para "se va" o `0` para "se queda") por cada observaci√≥n que hayas pasado en `X_new`.

---

### $X$: La Matriz de Atributos (2D)

La $X$ siempre es una **matriz**. En t√©rminos de programaci√≥n, es una "lista de listas" o un array de dos dimensiones.

- **Las Filas:** Representan a cada **sujeto u observaci√≥n** (en nuestro ejemplo, cada invitado).
    
- **Las Columnas:** Representan las **caracter√≠sticas o atributos** (features) que estamos midiendo de ese sujeto.
    

Aunque solo tengas **un solo atributo** (por ejemplo, cu√°ntas cervezas tom√≥ cada invitado), scikit-learn sigue esperando una estructura de tabla (2D).

> üí° **La analog√≠a del expediente:** Imagina que tienes un archivero. Cada carpeta es una fila (un invitado). Dentro de la carpeta hay varias hojas, cada una con un dato (edad, hambre, humor). Eso es 2D: **Filas (personas) x Columnas (datos).**

---

### $y$: El Vector Objetivo (1D)

La $y$ es un **vector**. Es una sola columna, una lista simple.

- **¬øPor qu√© es 1D?** Porque para cada observaci√≥n (cada fila de $X$), solo queremos predecir **una sola cosa**. En nuestro ejemplo: ¬øSe divirti√≥? (S√≠/No).
    
- No necesitas columnas extra, porque $y$ es simplemente la "etiqueta" o la respuesta final vinculada a cada fila de $X$.
    

---

### ¬øC√≥mo se ve esto en c√≥digo?

Si intentas pasarle a scikit-learn una lista simple para $X$, te lanzar√° un error porque espera "forma de tabla". Mira la diferencia:

Python

```
# Esto es 1D (Forma de 'y')
# Una lista simple de resultados
y = [1, 0, 1] 

# Esto es 2D (Forma de 'X')
# Aunque solo sea un dato por persona, nota los corchetes dobles [[ ]]
# Es una tabla de 3 filas y 1 columna
X = [
    [10], # Invitado 1 tom√≥ 10 cervezas
    [2],  # Invitado 2 tom√≥ 2 cervezas
    [8]   # Invitado 3 tom√≥ 8 cervezas
]
```

### ¬øPor qu√© scikit-learn es tan "especial" con esto?

Porque los algoritmos est√°n dise√±ados matem√°ticamente para realizar operaciones de **√°lgebra lineal**. Multiplican la matriz $X$ por un conjunto de pesos. Si $X$ no tiene forma de matriz (2D), la matem√°tica "no encaja" y el programa truena.

---

**Resumen r√°pido para tus notas:**

- **$X$ (Features):** Siempre **2D** `[Filas, Columnas]`. Es la informaci√≥n que describe al objeto.
    
- **$y$ (Target):** Siempre **1D** `[Resultados]`. Es la respuesta que queremos predecir.
    
