Este ejercicio es fundamental para visualizar el concepto del "punto dulce" en el Machine Learning. Al probar diferentes valores de $k$, estamos buscando el equilibrio perfecto entre un modelo que memoriza (sobreajuste) y uno que no aprende lo suficiente (infraajuste).

---

## An치lisis de Sobreajuste e Infraajuste

El objetivo de evaluar la complejidad del modelo es encontrar un punto donde el algoritmo generalice bien ante nuevas observaciones, evitando los dos errores cl치sicos:

- **Sobreajuste (Overfitting):** El modelo es demasiado complejo y se ajusta perfectamente a los datos de entrenamiento pero falla con los de prueba.
    
- **Infraajuste (Underfitting):** El modelo es demasiado simple y no logra capturar la relaci칩n entre las caracter칤sticas y el objetivo.
    

### Implementaci칩n del ciclo de evaluaci칩n

Para encontrar el valor 칩ptimo de $k$, iteramos sobre un rango de vecinos y almacenamos su precisi칩n.

```python
import numpy as np
from sklearn.neighbors import KNeighborsClassifier

# 1. Crear el rango de vecinos (1 a 12 inclusive)
neighbors = np.arange(1, 13)
train_accuracies = {}
test_accuracies = {}

for neighbor in neighbors:
  
	# 2. Instanciar el modelo con el iterador actual
	knn = KNeighborsClassifier(n_neighbors=neighbor)
  
	# 3. Ajustar el modelo a los datos de entrenamiento
	knn.fit(X_train, y_train)
  
	# 4. Calcular y almacenar precisiones
	# Usamos .score() que devuelve la exactitud (accuracy)
	train_accuracies[neighbor] = knn.score(X_train, y_train)
	test_accuracies[neighbor] = knn.score(X_test, y_test)
print(neighbors, '\n', train_accuracies, '\n', test_accuracies)
```

---

### Visualizaci칩n: La Curva de Complejidad

Una vez que tenemos los datos, el siguiente paso es graficarlos para tomar una decisi칩n informada. El c칩digo de complemento utiliza `matplotlib` para generar esta curva.

```python
import matplotlib.pyplot as plt

# Configurar el gr치fico
plt.figure(figsize=(8, 6))
plt.title('KNN: Variando el n칰mero de vecinos')

# Graficar precisi칩n de entrenamiento
plt.plot(neighbors, train_accuracies.values(), label='Precisi칩n Entrenamiento')

# Graficar precisi칩n de prueba
plt.plot(neighbors, test_accuracies.values(), label='Precisi칩n Prueba')

plt.legend()
plt.xlabel('N칰mero de Vecinos (k)')
plt.ylabel('Exactitud (Accuracy)')
plt.show()
```

### Interpretaci칩n de la gr치fica

Al observar la curva resultante, podemos identificar el comportamiento del modelo:

- **A la izquierda ($k$ bajos):** Notar치s que la precisi칩n del entrenamiento es muy alta (cercana al 1.0), mientras que la de prueba es menor. Aqu칤 el modelo est치 **sobreajustado**.
    
- **A la derecha ($k$ altos):** Ambas precisiones tienden a bajar y estabilizarse. Si bajan demasiado, el modelo est치 **infraajustado**.
    
- **El punto 칩ptimo:** Es el valor de $k$ en el eje horizontal donde la **Precisi칩n de Prueba** alcanza su valor m치ximo. Este es el modelo que mejor generalizar치 con datos reales del mundo de las telecomunicaciones.
    
Este es el paso final para cerrar el ciclo de evaluaci칩n de tu modelo. Generar la gr치fica te permite ver de forma clara qu칠 valor de $k$ es el m치s equilibrado.

Aqu칤 tienes el c칩digo completado y la explicaci칩n de c칩mo interpretar lo que ver치s en pantalla.

---

## Visualizar la complejidad del modelo

Una vez que hemos probado distintos valores para el n칰mero de vecinos ($k$), la mejor forma de tomar una decisi칩n es mediante una **Curva de Complejidad**. Esta gr치fica nos muestra c칩mo cambia la exactitud (accuracy) tanto en los datos que el modelo ya conoce (entrenamiento) como en los que son nuevos para 칠l (prueba).


```python
import matplotlib.pyplot as plt

# 1. A침adimos el t칤tulo al gr치fico
plt.title("KNN: Varying Number of Neighbors")

# 2. Trazamos la precisi칩n de entrenamiento
# Usamos .values() porque las precisiones est치n guardadas en un diccionario
plt.plot(neighbors, train_accuracies.values(), label="Training Accuracy")

# 3. Trazamos la precisi칩n de prueba
plt.plot(neighbors, test_accuracies.values(), label="Testing Accuracy")

# Configuraciones adicionales para que el gr치fico sea legible
plt.legend()
plt.xlabel("Number of Neighbors")
plt.ylabel("Accuracy")

# 4. Visualizamos el gr치fico final
plt.show()
```

---

### 쮺칩mo interpretar este apunte visual?

Para entender esta gr치fica, imagina que est치s calibrando la sensibilidad de un sensor:

- **La l칤nea de "Training Accuracy" (Entrenamiento):** Siempre suele empezar muy alta cuando $k$ es peque침o. Esto es porque con pocos vecinos, el modelo es muy "detallista" y se acuerda perfectamente de casi todos los puntos de entrenamiento. A medida que $k$ aumenta, esta l칤nea suele bajar porque el modelo se vuelve m치s general.
    
- **La l칤nea de "Testing Accuracy" (Prueba):** Esta es la que realmente nos importa.
    
    - Si $k$ es muy bajo, la precisi칩n de prueba es baja comparada con la de entrenamiento (**Sobreajuste**).
        
    - Si $k$ es muy alto, ambas l칤neas bajan porque el modelo se vuelve "perezoso" y no distingue patrones (**Infraajuste**).
        

> 游눠 **El punto ideal:** Debes buscar el punto m치s alto en la l칤nea de **Testing Accuracy**. En el conjunto de datos de _churn_ que est치s usando, ver치s que el mejor rendimiento se encuentra cuando el n칰mero de vecinos es aproximadamente **7 o 9**. Ese es el valor de $k$ que deber칤as elegir para tu modelo final.

