La validaci贸n cruzada es una herramienta esencial para maximizar el uso de los datos disponibles, permitiendo que cada observaci贸n sea utilizada tanto para el entrenamiento como para la prueba. En este ejercicio, implementaremos una validaci贸n cruzada de 6 pliegues utilizando el gasto en **redes sociales** para predecir las **ventas**. El objetivo es observar la consistencia del modelo analizando el puntaje individual de cada uno de los pliegues (_folds_).

```python
# Importar los m贸dulos necesarios
from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LinearRegression

# Crear el objeto KFold
# Configuramos 6 divisiones, barajamos los datos y fijamos la semilla en 5
kf = KFold(n_splits=6, shuffle=True, random_state=5)

# Instanciar el modelo de regresi贸n lineal
reg = LinearRegression()

# Ejecutar la validaci贸n cruzada de 6 pliegues
# Pasamos el modelo, las caracter铆sticas (X), el objetivo (y) y el objeto kf a cv
cv_scores = cross_val_score(reg, X, y, cv=kf)

# Imprimir los resultados de cada pliegue
print(cv_scores)
```

---

### An谩lisis de la Validaci贸n Cruzada de 6 pliegues

Al realizar este proceso, obtenemos una visi贸n mucho m谩s profunda del rendimiento del modelo que con un simple corte de datos.

- **Interpretaci贸n de `cv_scores`**: El resultado es un arreglo de seis n煤meros. Cada uno representa el coeficiente de determinaci贸n ($R^2$) obtenido en una de las seis iteraciones. Si los n煤meros son muy similares entre s铆 (por ejemplo, todos rondando el 0.75), el modelo es **robusto**. Si hay mucha variaci贸n (uno da 0.90 y otro 0.40), el modelo es **inestable** y depende demasiado de c贸mo se elijan los datos.
    
- **El objeto `KFold`**:
    
    - `n_splits=6`: Divide el dataset en 6 partes iguales.
        
    - `shuffle=True`: Es una buena pr谩ctica barajar los datos, especialmente si el dataset original tiene alg煤n orden (por ejemplo, datos por fecha), para evitar que un pliegue se quede solo con datos de una tendencia espec铆fica.
        
    - `random_state=5`: Garantiza que, si otra persona corre el c贸digo, obtenga exactamente las mismas divisiones y resultados.
        
- **Importancia del $R^2$ en cada pliegue**: Al visualizar los seis puntajes, puedes detectar si existen subconjuntos de datos donde el modelo falla catastr贸ficamente. Esto te ayuda a entender si la relaci贸n entre "redes sociales" y "ventas" es constante en todo el conjunto de datos o si hay anomal铆as que debas investigar.
    

---
Tras ejecutar la validaci贸n cruzada y obtener los puntajes individuales para cada pliegue (_fold_), el siguiente paso l贸gico es resumir esos datos para obtener conclusiones estad铆sticas s贸lidas. En este ejercicio, calcularemos la **media** para conocer el desempe帽o promedio, la **desviaci贸n t铆pica** para medir la estabilidad del modelo y el **intervalo de confianza del 95%** para determinar el rango de precisi贸n m谩s probable.

```python
# Imprimir la media de los resultados (Mean)
# Representa el rendimiento promedio esperado del modelo
print(np.mean(cv_results))

# Imprimir la desviaci贸n t铆pica (Standard Deviation)
# Mide qu茅 tanto var铆an los resultados entre cada pliegue
print(np.std(cv_results))

# Visualizar el intervalo de confianza del 95%
# Usamos los cuantiles 0.025 y 0.975 para obtener el 95% central
print(np.quantile(cv_results, [0.025, 0.975]))
```

---

### An谩lisis de M茅tricas Estad铆sticas en ML

Cuando hablamos de validaci贸n cruzada, un solo n煤mero no cuenta la historia completa. Necesitamos entender la dispersi贸n de los datos para confiar en el modelo.

#### 1. La Media ($\mu$)

Es el valor promedio de los coeficientes de determinaci贸n ($R^2$) obtenidos. Si tu media es de 0.75, puedes decir que, en promedio, tu modelo explica el 75% de la variabilidad de las ventas. Es nuestra mejor estimaci贸n del rendimiento real.

#### 2. La Desviaci贸n T铆pica ($\sigma$)

Esta m茅trica es el "term贸metro" de la consistencia.

- **Baja desviaci贸n:** El modelo es estable; no importa c贸mo cortes los datos, siempre rinde igual.
    
- **Alta desviaci贸n:** El modelo es inestable o "suertudo"; su rendimiento cambia dr谩sticamente dependiendo de los datos que le toquen para entrenar.
    

#### 3. Intervalo de Confianza del 95%

A diferencia de la media, que es un punto 煤nico, el intervalo de confianza nos da un **rango**.

- Al calcular `np.quantile(cv_results, [0.025, 0.975])`, estamos diciendo: "Tenemos un 95% de seguridad de que el $R^2$ de nuestro modelo cuando vea datos nuevos estar谩 entre el valor A y el valor B".
    
- Esto es vital para presentar resultados a clientes o jefes, ya que muestra el nivel de incertidumbre del proyecto.
    

>  **Tip de Pro:** Si tu desviaci贸n est谩ndar es mayor a 0.1 o 0.15 en un problema de regresi贸n, es una se帽al de alerta de que tu modelo podr铆a estar sufriendo de alta varianza (sobreajuste) o que tu dataset es demasiado peque帽o y poco representativo.
