La regresi칩n es el otro gran pilar del aprendizaje supervisado. Mientras que en la clasificaci칩n busc치bamos etiquetas (쯘s perro o gato?), en la regresi칩n buscamos **predecir n칰meros dentro de un rango continuo**.

Aqu칤 tienes tu apunte refinado, enriquecido con analog칤as y los detalles t칠cnicos que vimos en el video.

---

## Introducci칩n a la Regresi칩n

La regresi칩n es la tarea de predecir un valor num칠rico espec칤fico. A diferencia de la clasificaci칩n, donde los resultados son categor칤as discretas, en la regresi칩n los resultados pueden ser **infinitos** dentro de una escala.

### Definici칩n y Caracter칤sticas

**Definici칩n:** Es un proceso estad칤stico y de ML que estima las relaciones entre variables. Se utiliza para predecir una **variable objetivo (target)** continua bas치ndose en una o m치s **caracter칤sticas (features)**.

**Caracter칤sticas principales:**

- **Continuidad:** El valor de salida es un n칰mero real (ej. 15.5, 100.2, 1000.0).
    
- **Correlaci칩n:** Busca entender c칩mo cambia la variable objetivo cuando una caracter칤stica se mueve (ej. si el IMC sube, 쯥ube la glucosa?).
    
- **L칤nea de mejor ajuste (Line of Best Fit):** El objetivo matem치tico es trazar una l칤nea que pase lo m치s cerca posible de todos los puntos de datos.
    

---

### Ejemplos del Mundo Real

- **Econom칤a:** Predecir el PIB (Producto Interno Bruto) de un pa칤s.
    
- **Bienes Ra칤ces:** Estimar el precio de una casa seg칰n sus metros cuadrados y ubicaci칩n.
    
- **Salud (Caso de estudio):** Predecir los niveles de **glucosa en sangre** bas치ndose en el 칈ndice de Masa Corporal (IMC).
    

---

### Preparaci칩n de Datos: El reto del Array 2D

En el video vimos que `scikit-learn` es muy exigente con la forma de los datos, especialmente cuando usamos una **sola caracter칤stica** (regresi칩n univariada).

#### El problema de la dimensi칩n

Si extraemos una sola columna (como el IMC), Python nos da un array de una dimensi칩n (1D). Pero `scikit-learn` siempre espera que $X$ sea una matriz (2D).

#### La soluci칩n: `.reshape()`

Para convertir un array de una lista simple a una "columna de tabla", usamos NumPy:


```python
# -1 significa "mant칠n todas las filas", 1 significa "hazlo una sola columna"
X_bmi = X_bmi.reshape(-1, 1)
```

---

### Flujo de Trabajo: Regresi칩n Lineal

La **Regresi칩n Lineal** es el algoritmo m치s b치sico. Intenta ajustar una l칤nea recta a los datos siguiendo la ecuaci칩n:

$$y = ax + b$$

Donde **$a$** es la pendiente (qu칠 tanto afecta la $X$ a la $y$) y **$b$** es la intersecci칩n (d칩nde corta el eje vertical).

#### Pasos en c칩digo:

1. **Importar:** `from sklearn.linear_model import LinearRegression`
    
2. **Instanciar:** `reg = LinearRegression()`
    
3. **Ajustar (Fit):** `reg.fit(X_bmi, y)` (Aqu칤 el modelo encuentra los valores 칩ptimos de $a$ y $b$).
    
4. **Predecir:** `predictions = reg.predict(X_bmi)`
    

### Visualizaci칩n de resultados

Al graficar, ver치s dos capas:

1. **Scatter plot:** Los puntos reales de los pacientes.
    
2. **Line plot:** La l칤nea negra que representa la predicci칩n del modelo.
    

Si la l칤nea sube hacia la derecha, tenemos una **correlaci칩n positiva**: a mayor IMC, mayor nivel de glucosa esperado.
Tienes raz칩n, vamos a aterrizar los detalles t칠cnicos y el flujo de c칩digo que se present칩 en el video para que tu apunte sea totalmente funcional. Aqu칤 tienes la continuaci칩n centrada en la implementaci칩n con **scikit-learn** y **NumPy**.

---

## Implementaci칩n de Regresi칩n Lineal

En este ejemplo, el objetivo es predecir los niveles de glucosa en sangre utilizando el 칈ndice de Masa Corporal (IMC o BMI) como caracter칤stica principal.

### Preparaci칩n de las Matrices: X e y

Para trabajar con scikit-learn, debemos separar los datos en dos variables distintas. Una convenci칩n com칰n en Python es usar los atributos de **Pandas** y convertirlos a arreglos de **NumPy**.

- **Crear X (Caracter칤sticas):** Eliminamos la columna objetivo del DataFrame original.
    
- **Crear y (Objetivo):** Seleccionamos 칰nicamente la columna que queremos predecir.
    

```python
# Eliminamos la columna 'glucose' para dejar solo las caracter칤sticas
X = diabetes_df.drop("glucose", axis=1).values

# Seleccionamos solo la columna 'glucose' como nuestro objetivo
y = diabetes_df["glucose"].values
```

### El Reto de la Dimensi칩n: Reshape de X

Cuando realizamos una regresi칩n con **una sola caracter칤stica** (como solo el IMC), scikit-learn requiere que esa columna se comporte como una matriz (2D), no como una lista simple (1D).

Si tomamos la columna 4 de nuestra matriz $X$ (que corresponde al IMC):

```python
import numpy as np

# Extraemos la columna del IMC
X_bmi = X[:, 3] 

# El truco del Reshape
# -1 le dice a NumPy: "calcula t칰 el n칰mero de filas"
# 1 le dice: "pero d칠jame solo una columna"
X_bmi = X_bmi.reshape(-1, 1)

print(X_bmi.shape) # Resultado esperado: (N, 1)
```

> 游눠 **Analog칤a del estante:** Imagina que tienes una fila de libros en el suelo (1D). Scikit-learn es un estante que solo acepta cajas. El `reshape` es como meter cada libro en una caja individual y apilarlas una sobre otra para que ahora tengan una estructura de "columna" (2D).

---

### Ajuste y Predicci칩n del Modelo

Una vez que los datos tienen la forma correcta, seguimos el flujo est치ndar de `sklearn`.


```python
from sklearn.linear_model import LinearRegression

# 1. Instanciar el modelo
reg = LinearRegression()

# 2. Ajustar (Entrenar) el modelo con los datos
# Aqu칤 el modelo busca la l칤nea que mejor se adapta a los puntos
reg.fit(X_bmi, y)

# 3. Realizar predicciones
# Usamos los mismos datos de X para ver d칩nde queda la l칤nea de ajuste
predictions = reg.predict(X_bmi)
```

### Visualizaci칩n del Modelo

Para entender visualmente qu칠 hizo el modelo, superponemos los datos reales con la l칤nea de predicci칩n.

```python
import matplotlib.pyplot as plt

# Graficamos los puntos reales (Dispersi칩n)
plt.scatter(X_bmi, y, color="blue", alpha=0.5)

# Graficamos la l칤nea de predicci칩n (Regresi칩n)
plt.plot(X_bmi, predictions, color="black", linewidth=3)

plt.xlabel("칈ndice de Masa Corporal (BMI)")
plt.ylabel("Glucosa en Sangre")
plt.show()
```

### Interpretaci칩n de la Gr치fica

- **Los puntos azules:** Representan a cada paciente real. Notar치s que hay mucha dispersi칩n; esto es normal en datos biol칩gicos.
    
- **La l칤nea negra:** Es la **L칤nea de Mejor Ajuste**. Representa la tendencia general.
    
- **Conclusi칩n visual:** Existe una **correlaci칩n positiva d칠bil a moderada**. Esto significa que, estad칤sticamente, a medida que aumenta el IMC, los niveles de glucosa en sangre tienden a subir, aunque no de forma exacta para todos los individuos.
    