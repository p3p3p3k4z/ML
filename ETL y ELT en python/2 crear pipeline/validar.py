import pandas as pd

# =================================================================
# PIPELINE ETL CON VALIDACI√ìN DE CALIDAD (DATA OBSERVABILITY)
# Prop√≥sito: Extraer datos Parquet, filtrar pedidos unitarios 
#            y validar que el resultado cumpla los est√°ndares.
# =================================================================

def extract(file_path):
    """
    Fase de Extracci√≥n: Lectura de formato columnar.
    POR QU√â: Parquet es m√°s eficiente que CSV para grandes vol√∫menes.
    """
    print(f"üì¶ [EXTRACT] Leyendo archivo: {file_path}")
    try:
        # Usamos read_parquet para mantener los tipos de datos nativos
        return pd.read_parquet(file_path)
    except Exception as e:
        print(f"‚ùå Error en extracci√≥n: {e}")
        return None

def transform(raw_data):
    """
    Fase de Transformaci√≥n: Poda de datos.
    POR QU√â: Reducir la dimensionalidad mejora el rendimiento del sistema.
    """
    print("üõ†Ô∏è [TRANSFORM] Filtrando pedidos unitarios y seleccionando columnas...")
    
    # Filtramos filas: Solo Quantity Ordered == 1
    # Seleccionamos columnas: Order ID, Price Each, Quantity Ordered
    clean_data = raw_data.loc[
        raw_data["Quantity Ordered"] == 1, 
        ["Order ID", "Price Each", "Quantity Ordered"]
    ]
    return clean_data

def validate(df):
    """
    Fase de Validaci√≥n (Sanity Check):
    POR QU√â: En DevOps, 'fallar r√°pido' es mejor que cargar datos err√≥neos.
    """
    print("‚öñÔ∏è [VALIDATE] Iniciando pruebas de calidad de datos...")
    
    # 1. Validaci√≥n de Integridad: ¬øEl DataFrame est√° vac√≠o?
    if df.empty:
        print("‚ö†Ô∏è Advertencia: El DataFrame resultante no tiene registros.")
        return False
    
    # 2. Validaci√≥n de Filtro: ¬øRealmente solo hay pedidos de cantidad 1?
    # Usamos .unique() para verificar los valores distintos en la columna
    unique_quantities = df["Quantity Ordered"].unique()
    if len(unique_quantities) == 1 and unique_quantities[0] == 1:
        print("‚úÖ Prueba de Filtro: PASADA (Solo valores de 1 encontrados).")
    else:
        print(f"‚ùå Prueba de Filtro: FALLIDA. Valores encontrados: {unique_quantities}")
        return False

    # 3. Validaci√≥n de Nulos: ¬øHay datos faltantes en columnas cr√≠ticas?
    null_counts = df.isnull().sum().sum()
    if null_counts == 0:
        print("‚úÖ Prueba de Nulos: PASADA (0 valores nulos).")
    else:
        print(f"‚ùå Prueba de Nulos: FALLIDA. Se encontraron {null_counts} nulos.")
        return False

    print("üöÄ Validaci√≥n completa: Datos listos para la carga.")
    return True

# =================================================================
# ORQUESTACI√ìN PRINCIPAL
# =================================================================

# 1. Extraer
raw_sales_data = extract("sales_data.parquet")

if raw_sales_data is not None:
    # 2. Transformar
    clean_sales_data = transform(raw_sales_data)
    
    # 3. Validar
    # Solo si la validaci√≥n es exitosa, proceder√≠amos al siguiente paso (Load)
    if validate(clean_sales_data):
        print("\n--- RESUMEN FINAL ---")
        print(clean_sales_data.head())
        print(f"Total de registros validados: {len(clean_sales_data)}")
    else:
        print("üõë Proceso detenido: Los datos transformados no pasaron las pruebas.")
