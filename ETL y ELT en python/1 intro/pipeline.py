import pandas as pd
import os

# =================================================================
# PIPELINE ETL: GESTI√ìN DE DATOS INDUSTRIALES / ESTUDIANTILES
# Prop√≥sito: Extraer m√©tricas crudas, filtrar informaci√≥n cr√≠tica 
#            y asegurar la persistencia para an√°lisis posterior.
# =================================================================

def extract(file_name):
    """
    PROP√ìSITO: Punto de entrada del pipeline.
    POR QU√â: Centralizar la lectura permite manejar errores de I/O 
    (Input/Output) en un solo lugar. Si el origen cambia de un CSV 
    a una base de datos SQL, solo modificamos esta funci√≥n.
    """
    print(f"üîç [EXTRACT] Accediendo a la fuente: {file_name}")
    try:
        return pd.read_csv(file_name)
    except FileNotFoundError:
        print(f"‚ùå Error: El archivo {file_name} no existe.")
        return None

def transform(data_frame):
    """
    PROP√ìSITO: Refinamiento y l√≥gica de negocio.
    POR QU√â: 
    1. Optimizaci√≥n: Reducimos el uso de memoria RAM al descartar 
       columnas innecesarias.
    2. Seguridad: Evitamos que datos sensibles viajen al destino final.
    3. Rendimiento: El filtrado con .loc es vectorizado y eficiente.
    """
    print("üõ†Ô∏è [TRANSFORM] Filtrando columnas cr√≠ticas...")
    # Seleccionamos solo industry_name y number_of_firms
    # Usamos .loc para asegurar que trabajamos sobre la estructura correcta
    columns_to_keep = ["industry_name", "number_of_firms"]
    return data_frame.loc[:, columns_to_keep]

def load(data_frame, file_name):
    """
    PROP√ìSITO: Persistencia de estado (Output).
    POR QU√â: El valor del ETL reside en que el resultado sea consultable. 
    Usamos index=False para evitar 'poluci√≥n de datos' (columnas de 
    √≠ndices innecesarias en el CSV de salida).
    """
    print(f"üíæ [LOAD] Guardando datos transformados en: {file_name}")
    data_frame.to_csv(file_name, index=False)
    print("‚úÖ Carga finalizada con √©xito.")

# =================================================================
# ORQUESTACI√ìN DEL PROCESO
# =================================================================

def run_etl_pipeline():
    # 1. Fase de Extracci√≥n
    raw_data_path = "raw_data.csv"
    extracted_data = extract(raw_data_path)
    
    if extracted_data is not None:
        # 2. Fase de Transformaci√≥n
        transformed_data = transform(extracted_data)
        
        # 3. Fase de Carga
        output_path = "number_of_firms.csv"
        load(transformed_data, output_path)
    else:
        print("üõë Pipeline detenido: No se pudo obtener la fuente de datos.")

if __name__ == "__main__":
    run_etl_pipeline()
